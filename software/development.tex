\namedsection{Developing for a Limited Environment}{Shepherd}
% This section talks about the C development

The Multilayer Perceptron is a good fit for a subthreshold Cortex M0+ as it does not require a great deal of complex mathematical computation. Unfortuneately, however, it does require the use of decimal numbers and uses the sigmoid function, which requires division and power operations. This section discusses some of the design decisions and sacrifices that were made in order to implement an MLP on the subthreshold Cortex M0+.

\subsection{Sigmoid Function}
The sigmoid function's graph and equation is shown below in figure \ref{fig:sigmoid}. Clearly, this equation causes two issues for the proposed device: firstly, it requires division, and secondly it requires the use of the constant e, which is a non-integer; using this in an operation involving powers could potentially prove expensive.

The first area of note in this graph is that the value of $f(t)$ quickly starts to tend towards 0 in the negative direction, and 1 in the positive direction. It is not uncommon, therefore, to approximate the value of the function at these extremes. Figure \ref{fig:sigmoid-ends} shows this approximation highlighted in blue for t values outside of the range between 5 and -5; it is plain to see that the error introduced here is minimal. On average, we have found that approximately 42\% \todo{REF needed} of nodes produce values in outside this range meaning they can be approximated to 0 or 1 without wasting any processing power on completing the full sigmoid function.

\begin{figure}[!h]
    \centering
    \subfigure[Normal Sigmoid Function]{\label{fig:sigmoid}\includegraphics[width=70mm]{figures/sigmoid.pdf}}
    \subfigure[Approximated Ends]{\label{fig:sigmoid-ends}\includegraphics[width=70mm]{figures/sigmoid-ends.pdf}}
    \subfigure[Approximated With Lines]{\label{fig:sigmoid-soft}\includegraphics[width=70mm]{figures/sigmoid-soft.pdf}}
    \subfigure[Approximated With Linear Equation]{\label{fig:sigmoid-hard}\includegraphics[width=70mm]{figures/sigmoid-hard.pdf}}
    \caption{Sigmoid Functions \label{fig:sigmoid-options}}
\end{figure}

For the remaining range, between 5 and -5, the sigmoid function does not tend to any fixed value, so a different approximation must be used. Fortuneately, the sigmoid's ``S''-like shape lends itself to being easily split into a series of smaller lines, as shown in figure \ref{fig:sigmoid-soft}. This provides a suitable level of accuracy with far lower computing overhead as each line can be defined using only a linar equation. However, as beneficial as the approximation in figure \ref{fig:sigmoid-soft} is, it is possible to approximate this further. We have found that approximating the sigmoid function with a single linear equation has proved satisfactory and has only lead to an observed drop in accuracy by 1\% \todo{REF}. This is shown in this section's final figure: \ref{fig:sigmoid-hard}.

\subsection{Floating point}
The lack of floating point support in the proposed device created a large challenge, as the neural network is entirely based upon a series of non-integer input weights, and the ability for each node to produce non integer output values. In order to get around this problem, the team opted for a fixed-point implementation: the weights of each node are multiplied by a scale factor and the resulting integer part is taken as the value.

This form is convienient as it makes the multiplication and addition of such scaled values straight forward: for addition of values using the same scale factor, it is sufficient to simply add the integers as though they were normal. The equation below illustrates this:

\begin{equation}
\label{eq:bits:addition}
x*S+y*S=(x+y)*S
\end{equation}

For the case of multiplation, the scale factors of each number must be added, meaning that when two numbers with a scale factor of $S$ are multiplied, the resulting number's scale factor is $S^2$:

\begin{equation}
\label{eq:bits:multiplication}
(x*S)(y*S)=(x*y)*S^2
\end{equation}

This can be easily rectified by simplying dividing the result by $S$ again to return to the original scale factor:

\begin{equation}
\label{eq:bits:rescale}
\frac{(x*y)*S^2}{S}=(x*y)*S
\end{equation}

As division is not supported on our system, we have defined our scale factor $S$ as a power of 2: $S=2^B$. We are then able to approximate divisions of powers of 2, by simply performing a bitshift:

\begin{equation}
\label{eq:bits:div_approx}
X/2^B\approx X \gg B
\end{equation}

\subsubsection{Using this on the Device}

To decide the bit scale factor, $B$, for the exercise detection algorithm, it is important to consider the memory restrictions on variable size. At a hardware level, 32bits, or 4 bytes, is the maximum size an integer can be. As the algorithm requires the multiplication of numbers, ideally these would need to fit into just a 2 bytes space, as the multiplication of numbers results in the addition of powers, as shown in equation \ref{eq:bits:multiplication-shift}.

\begin{equation}
\label{eq:bits:multiplication-shift}
(x*2^B)(y*2^B)=(x*y)*(2^B)^2=(x*y)*2^{2B}
\end{equation}

As such, the value of $B$ has to be high enough such that precision is not lost unnessisarily, but low enough such that $x*2^B<2^{16}$. Solve this, the highest possible floating point value must be known; in the case of the algorithm, this is the base value of the first node in the middle layer: -10.6 (3s.f.), using this in the rearranged equation, \ref{eq:bits:number-calc}, gives a bitshift of 12.

\begin{equation}
\label{eq:bits:number-calc}
B<\lfloor\log_{2}\left\{\frac{2^{16}}{|x|}\right\}\rfloor
\end{equation}

\subsection{Space Restrictions}

As described in \ref{section}, the device has very little memory space availiable: 8KB for both program code and data. When the algorithm code was first compiled with the mBed's precompiled libraries, the total size of the binary was 12KB. The first step to solve this was to obtain the source code for the mBed libraries; compiling these directly along with the program code, offers further potencial for the compiler to optimise the link between the API and the algorithm, based on the specific usecase.

The method was successful at reducing the total binary size to 8KB. This was a substancial improvement, however it was clear that this would need to be decreased further as it an 8KB binary leaves no space for heap or stack space when the code is run.

\subsubsection{Improving GCC's Optimisations}

While ARM's compiler is very good at optimising code when it compiles C and C++ code, the linker is not able to do so many of the same optimisations across compilation units. It was a logical first step, therefore, to identify the functions and classes that the program code calls within the mBed's api to investigate the benefits of combining their compilation unit.

In many cases, specific API calls were only made once from the algorithm code, such as the call to \verb|ic2_init()| which gets the I2C ready to communicate with the processor at the beginning of the program. Within a library, it is logical to ensure such a function remains an atomic and referenceable item, as it is feasible for a device to use more than one I2C device; as such the call may need to be made multiple times and with varying parameters.

However, as it was only called once in this case, moving \verb|ic2_init()| into the same compilation unit as the function which calls it, replacing the call with the code itself inline. As a result, the compiler is no longer required to produce assembly instructions to copy in arguments and push a new frame onto the stack; this saves not only space, but improves the performance of the code too.

\subsubsection{Argument Guards}

The mBed API's functions also often came with guards on their arguments; for example, the function \verb|gpio_init()| which is used to initialise the LED pins, accepts a pin as an arguement. Before initialising the given pin, it checks that it was not passed the pseudo-pin ``Not Connected''.

\begin{lstlisting}[caption={Argument Guards of gpio init}]
void gpio_init(gpio_t *obj, PinName pin)
{
    if (pin == (PinName)NC) // NC = Not Connected
        return;

    // gpio_init code...
}
\end{lstlisting}

Again, such a check is appropriate for an API as incorrectly passing a null pin would cause an error should the code attempt to initialise it. However, in our program we can see which pins we are passing to this function, namely the LED pins, so we can be confident that we are not passing in the null \verb|NC| pin and as such it is safe to delete the check, reducing the number of instructions required.

\subsubsection{Pinmap Functions}

The mBed library is designed to be general purpose across multiple platforms. As such the library contains a layer of abstraction to help it interface with the pins and memory addresses for a specific device. For memory addresses, this abstraction is achieved using macros in device-specific header files, which allows optimisation to can happen at compile time:

\begin{lstlisting}[caption={Memory spaces mapped in LPC11Uxx.h}]
typedef struct {                 /*!< GPIO_GROUP_INT0 Structure */
    __IO uint32_t CTRL;          /*!< GPIO grouped interrupt control register */
    __I  uint32_t RESERVED0[7];
    __IO uint32_t PORT_POL[2];   /*!< Interrupt port 0 polarity register */
    __I  uint32_t RESERVED1[6];
    __IO uint32_t PORT_ENA[2];   /*!< Interrupt port 0/1 enable register */
} LPC_GPIO_GROUP_INTx_Type;

// Peripheral memory map
#define LPC_GPIO_PIN_INT_BASE     (0x4004C000)
#define LPC_GPIO_GROUP_INT0_BASE  (0x4005C000)
#define LPC_GPIO_GROUP_INT1_BASE  (0x40060000)

#define LPC_GPIO_GROUP_INT0 ((LPC_GPIO_GROUP_INTx_Type*) LPC_GPIO_GROUP_INT0_BASE)
#define LPC_GPIO_GROUP_INT1 ((LPC_GPIO_GROUP_INTx_Type*) LPC_GPIO_GROUP_INT1_BASE)
\end{lstlisting}

The above specifices the structure of the GPIO INT memory space, then defines the memory spaces and creates references to these. This allows the developer, and the libraries to use the constant pointers, as illustrated:

\begin{lstlisting}[caption={LPC GPIO GROUP INT0 being used}]
#include ``LPC11Uxx.h'';

void main()
{
    LPC_GPIO_GROUP_INT0_BASE->CTRL = 48;
}
\end{lstlisting}

The use of these definitions allows the compiler to optimise these to constant values, as shown with the assembly below:

\begin{lstlisting}[caption={LPC GPIO GROUP INT0 converted to ASM}]
main:
    str fp, [sp, #-4]! @ Stack Init
    add fp, sp, #0     @ Stack Init
    ldr r3, .L2        @ Value of memory space
    mov r2, #48        @ Using 48
    str r2, [r3]       @ Saving 48 to the memory space
    mov r0, r3
    sub sp, fp, #0
    @ sp needed
    ldr fp, [sp], #4
    bx  lr
.L3:
    .align  2
.L2:
    .word   1074118656 @ This is 0x4005C000
\end{lstlisting}

Unfortuneately, a similar technique is not used for the Pin Mappings. Instead, these are stored in an array within a C file which is specific to each target. The values in this array are worked upon in two seperate files - one common across all devices, and one common to the device's family. The reason this is done is that the pin mappings, and the way in which their modes are updated is more complex and as such is harder to achieve through the use of defined macros. However, as the result of this is that the pin mappings and pin functions are not contained within a single compilation unit, the linker is not able to perform the same optimisations as the compiler is.

This not only results in wasted space, as the pins and their functions must be stored as part of the program code, but it also wastes valueable clock cycles, calculating values for pin addresses which could in theory be precalculated. In order to avoid this, we worked through the pin functions manually from the point at which they were called and manually calculated the registers that would be used. We then replaced these with the hard coded register values.